{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "import tgt\n",
    "import math\n",
    "import sklearn\n",
    "import librosa\n",
    "import re\n",
    "import scipy.io.wavfile\n",
    "import parselmouth\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa.display\n",
    "from sklearn import metrics\n",
    "from scipy.signal import lfilter, hamming\n",
    "from textGrid_AudioTrim import readTextGridUpdate,audio_trimming\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formantLpc(newWavFile_vowel):\n",
    "    #preprocessing first step -->get the hamming window \n",
    "    x=newWavFile_vowel\n",
    "    N = len(x)\n",
    "    w = np.hamming(N)\n",
    "    #preprocessing step 2 --> apply the window and the high pass filter \n",
    "    # Apply window and high pass filter.\n",
    "    #issues to be fixed in this version of code is  \n",
    "    #a) how to choose the order in the lpc \n",
    "    #b) how to filter out the resultant frequency array \n",
    "    # c) how many formants to get \n",
    "    x1 = x * w\n",
    "    x1 = lfilter([1], [1., 0.63], x1)\n",
    "    Fs =16000\n",
    "    ncoeff = 2 + Fs / 1000\n",
    "    print(ncoeff)\n",
    "    A = librosa.core.lpc(x1, int(ncoeff))\n",
    "    rts = np.roots(A)\n",
    "    rts = rts[np.imag(rts) >= 0]\n",
    "    angz = np.arctan2(np.imag(rts), np.real(rts))\n",
    "    frqs = angz * (Fs / (2 *  np.pi))\n",
    "    frqs.sort()\n",
    "    \n",
    "    frqs=[i for i in frqs if(i>0.0 and i<=5500)]\n",
    "    \n",
    "    if(len(frqs)>=3):\n",
    "        return frqs[0:3]\n",
    "    else:\n",
    "        return frqs\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateFormantsPraat(formant,atTime):\n",
    "    formants=[]\n",
    "    for i in range(1,6):\n",
    "      #  print(i)\n",
    "        x=formant.get_value_at_time(i,atTime)\n",
    "        if(x!=0 and np.isnan(x)==False):\n",
    "            formants.append(x)\n",
    "    print(formants)\n",
    "    formants.sort()\n",
    "    if(len(formants)>=3):\n",
    "        return formants[0:3]\n",
    "    else:\n",
    "        return formants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFormantsPraat(start_time,end_time,sound,formantType):\n",
    "    point10=start_time+((end_time-start_time)*0.1)\n",
    "    point20 = start_time + ((end_time-start_time)*0.2)\n",
    "    point50 = start_time + ((end_time-start_time)*0.5)\n",
    "    point80 = end_time - ((end_time-start_time)*0.2)\n",
    "  \n",
    "   # print(\"start and end time for formants\",point20,point50,point80)\n",
    "    formant = sound.to_formant_burg(max_number_of_formants=5, maximum_formant=5500)\n",
    "    if(formantType==50):\n",
    "        formants=calculateFormantsPraat(formant,point50)\n",
    "        if(np.isnan(formants).all()==True):\n",
    "           \n",
    "            point50=point50+point10\n",
    "        formants=calculateFormantsPraat(formant,point50)\n",
    "        \n",
    "    elif(formantType==20):\n",
    "        formants=calculateFormantsPraat(formant,point20)\n",
    "        if(np.isnan(formants).all()==True):\n",
    "            \n",
    "            point20=point20+point10\n",
    "        formants=calculateFormantsPraat(formant,point20)\n",
    "        \n",
    "    \n",
    "    elif(formantType==80):\n",
    "        formants=calculateFormantsPraat(formant,point80)\n",
    "        if(np.isnan(formants).all()==True):\n",
    "           \n",
    "            point80=point80+point10\n",
    "        formants=calculateFormantsPraat(formant,point80)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    return formants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,formantType,formantMethod):\n",
    "    formants_vowel=[]\n",
    "    filenames=[]\n",
    "    SAMPLE_RATE=16000\n",
    "    i=0\n",
    "\n",
    "    for path in final_files:\n",
    "        filenames.append(path)\n",
    "        \n",
    "        try:\n",
    "            print(i)\n",
    "            i=i+1\n",
    "     \n",
    "            textGrid_file_path=os.path.join(base_path_textGrid,path)+'.TextGrid'\n",
    "            start_time_word,end_time_word,start_time_pronunciation_vowel,end_time_pronunciation_vowel=readTextGridUpdate(textGrid_file_path,word,pronunciation_vowel)\n",
    "            \n",
    "           # print(start_time_word,end_time_word,start_time_pronunciation_vowel,end_time_pronunciation_vowel)\n",
    "            audio_file_path=os.path.join(base_path_audio,path)+'.wav'\n",
    "            sound=parselmouth.Sound(audio_file_path)\n",
    "            \n",
    "            if(formantMethod=='praat'):\n",
    "                sound=parselmouth.Sound(audio_file_path)\n",
    "                formants=getFormantsPraat(start_time_pronunciation_vowel,end_time_pronunciation_vowel,sound,formantType)\n",
    "            \n",
    "            elif(formantMethod=='lpc'):\n",
    "                newWavFile_vowel=audio_trimming(audio_file_path,start_time_pronunciation_vowel,end_time_pronunciation_vowel)\n",
    "                formants=formantLpc(newWavFile_vowel)\n",
    "            \n",
    "            formants_vowel.append(formants)\n",
    "           # print(formants_vowel)\n",
    "           # print(filenames)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    \n",
    "    df_vowel=pd.DataFrame({'feature':formants_vowel})\n",
    "    df_vowel=df_vowel.feature.apply(pd.Series)\n",
    "    df_vowel['file_name']=filenames\n",
    "    \n",
    "    return df_vowel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#this is for muslim dataset\n",
    "if __name__==\"__main__\":\n",
    "    # three variables are needed here the two  basepaths and the dataframe path\n",
    "    # as an additional feature we can definitely ask for the feature to be extracted\n",
    "    base_path_textGrid=\"D://Himani-work/gsoc2020/dataset/muslim_dataset_version1/muslim_textGrid_dataset/\"\n",
    "    base_path_audio=\"D://Himani-work/gsoc2020/dataset/muslim_dataset_version1/muslim_wav_dataset/\"\n",
    "    \n",
    "    textGridFiles=list(os.listdir(base_path_textGrid))\n",
    "    audioFiles=list(os.listdir(base_path_audio))\n",
    "    all_audio_files=list(pd.DataFrame({'audioFile':audioFiles})['audioFile'].str.split(\".wav\",expand=True).iloc[:,0])\n",
    "    all_textGrid_files=list(pd.DataFrame({'textGridFile':textGridFiles})['textGridFile'].str.split(\".TextGrid\",expand=True).iloc[:,0])\n",
    "    print(\"total texGrid and audio files\",len(all_audio_files),len(all_textGrid_files))\n",
    "    \n",
    "    df=pd.read_excel(\"D://Himani-work/gsoc2020/dataset/spreadsheet_data/muslim_concordance_250_annotated.xls\")\n",
    "    df.dropna(inplace=True)\n",
    "    all_correct_files=list(df['File Name'])\n",
    "    \n",
    "    print(\"total corrected files\",len(all_correct_files))\n",
    "    \n",
    "    final_files=list(set(all_audio_files)&set(all_correct_files)&set(all_textGrid_files))\n",
    "    print(\"final files\",len(final_files))\n",
    "    word=\"muslim\"\n",
    "    pronunciation_vowel=\"V\"\n",
    "    \n",
    "         \n",
    "    df_formant_20=extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,20,'praat')\n",
    "    df_formant_50=extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,50,'praat')\n",
    "    df_formant_80=extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,80,'praat')\n",
    "    df_formant_lpc=extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,0,'lpc')\n",
    "    \n",
    "    \n",
    "    df_formant_20.to_csv('D://Himani-work/gsoc2020/dataset/Audio_features/formants_20_muslim_features_vowel.csv',index=False)\n",
    "\n",
    "    df_formant_50.to_csv('D://Himani-work/gsoc2020/dataset/Audio_features/formants_50_muslim_features_vowel.csv',index=False)\n",
    "\n",
    "    df_formant_80.to_csv('D://Himani-work/gsoc2020/dataset/Audio_features/formants_80_muslim_features_vowel.csv',index=False)\n",
    "\n",
    "    df_formant_lpc.to_csv('D://Himani-work/gsoc2020/dataset/Audio_features/formants_lpc_muslim_features_vowel.csv',index=False)\n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if __name__==\"__main__\":\n",
    "    # three variables are needed here the two  basepaths and the dataframe path\n",
    "    # as an additional feature we can definitely ask for the feature to be extracted\n",
    "    base_path_textGrid=\"D://Himani-work/gsoc2020/dataset/ideology_five_words_version2/ideology_textGrid_five_dataset_version2/\"\n",
    "    base_path_audio=\"D://Himani-work/gsoc2020/dataset/ideology_five_words_version2/ideology_wav_five_dataset_version2/\"\n",
    "    \n",
    "    textGridFiles=list(os.listdir(base_path_textGrid))\n",
    "    audioFiles=list(os.listdir(base_path_audio))\n",
    "    all_audio_files=list(pd.DataFrame({'audioFile':audioFiles})['audioFile'].str.split(\".wav\",expand=True).iloc[:,0])\n",
    "    all_textGrid_files=list(pd.DataFrame({'textGridFile':textGridFiles})['textGridFile'].str.split(\".TextGrid\",expand=True).iloc[:,0])\n",
    "    print(\"total texGrid and audio files\",len(all_audio_files),len(all_textGrid_files))\n",
    "    \n",
    "    \n",
    "    \n",
    "    final_files=list(set(all_audio_files)&set(all_textGrid_files))\n",
    "    print(\"final files\",len(final_files))\n",
    "    \n",
    "    # Flow is like call the \n",
    "    word=r\"ideology\"\n",
    "    pronunciation_vowel=\"aI\"\n",
    "\n",
    "       \n",
    "    df_formant_20=extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,20,'praat')\n",
    "    df_formant_50=extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,50,'praat')\n",
    "    df_formant_80=extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,80,'praat')\n",
    "    df_formant_lpc=extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,0,'lpc')\n",
    "    \n",
    "    \n",
    "    df_formant_20.to_csv('D://Himani-work/gsoc2020/dataset/Audio_features/formants_20_ideology_five_features_vowel.csv',index=False)\n",
    "\n",
    "    df_formant_50.to_csv('D://Himani-work/gsoc2020/dataset/Audio_features/formants_50_ideology_five_features_vowel.csv',index=False)\n",
    "\n",
    "    df_formant_80.to_csv('D://Himani-work/gsoc2020/dataset/Audio_features/formants_80_ideology_five_features_vowel.csv',index=False)\n",
    "\n",
    "    df_formant_lpc.to_csv('D://Himani-work/gsoc2020/dataset/Audio_features/formants_lpc_ideology_five_features_vowel.csv',index=False)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if __name__==\"__main__\":\n",
    "    # three variables are needed here the two  basepaths and the dataframe path\n",
    "    # as an additional feature we can definitely ask for the feature to be extracted\n",
    "    base_path_textGrid=\"D://Himani-work/gsoc2020/dataset/ideology_extra200ms/textgrids_for_extra_200ms_MAUS/\"\n",
    "    base_path_audio=\"D://Himani-work/gsoc2020/dataset/ideology_extra200ms/with_extra_200ms\"\n",
    "    \n",
    "    textGridFiles=list(os.listdir(base_path_textGrid))\n",
    "    audioFiles=list(os.listdir(base_path_audio))\n",
    "    all_audio_files=list(pd.DataFrame({'audioFile':audioFiles})['audioFile'].str.split(\".wav\",expand=True).iloc[:,0])\n",
    "    all_textGrid_files=list(pd.DataFrame({'textGridFile':textGridFiles})['textGridFile'].str.split(\".TextGrid\",expand=True).iloc[:,0])\n",
    "    #print(\"total texGrid and audio files\",len(all_audio_files),len(all_textGrid_files))\n",
    "    \n",
    "    df_ideology_200ms=pd.read_csv('D:/Himani-work/gsoc2020/dataset/spreadsheet_data/ideology_results_praat_formants_extracted_with_200ms_for_R.csv',sep='\\t')\n",
    "    all_correct_files=list(df_ideology_200ms['file'].str.split(\"\\\\\",expand=True).iloc[:,-1].str.split(\".wav\",expand=True).iloc[:,0])\n",
    "   # print(\"total corrected files\",len(all_correct_files))\n",
    "    \n",
    "    final_files=list(set(all_audio_files)&set(all_correct_files)&set(all_textGrid_files))\n",
    "    #print(\"final files\",len(final_files))\n",
    "    \n",
    "     # Flow is like call the \n",
    "    word=\"ideology\"\n",
    "    pronunciation_vowel=\"aI\"\n",
    "\n",
    "    \n",
    "   # df_formant_20=extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,20,'praat')\n",
    "   # df_formant_50=extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,50,'praat')\n",
    "   # df_formant_80=extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,80,'praat')\n",
    "   # df_formant_lpc=extractAllFormants(final_files,base_path_textGrid,base_path_audio,word,pronunciation_vowel,0,'lpc')\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
